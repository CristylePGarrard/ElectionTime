# -*- coding: utf-8 -*-
"""extract_geo_data_for_districts.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CkvjPAZ_SacfkqAg2WTm6vVCvLYQsWY5
"""

!pip install geopandas requests gspread oauth2client

import pandas as pd
import geopandas as gpd
import requests
import json
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from gspread_dataframe import set_with_dataframe
from shapely.geometry import Point
import random

# Authenticate user with Google account
from google.colab import auth
auth.authenticate_user()

from google.auth import default

# Get creds from your logged-in account
creds, _ = default()
gc = gspread.authorize(creds)

# Open Google Sheet by title (the visible sheet name in Drive, not path)
spreadsheet = gc.open("UTsTateLegIslaTurE_02122025")
worksheet = spreadsheet.worksheet("Sheet1")

# Load data
data = worksheet.get_all_records()

df = pd.DataFrame(data)

df.head()
df.info()

# Function to reformat "Last, First Middle" → "First Middle Last"
def reformat_name(name):
    if pd.isna(name):
        return name
    parts = name.split(",")  # Split into ['Last', ' First Middle']
    if len(parts) != 2:
        return name.strip()  # If not in expected format, leave as-is
    last = parts[0].strip()
    first_middle = parts[1].strip()
    return f"{first_middle} {last}"

# Apply to the column
df['Representative'] = df['Representative'].apply(reformat_name)

# Check results
df[['Representative']].head(10)

# Create DistrictKey column
df["DistrictKey"] = df.apply(
    lambda row: ("H" if row["Office"] == "State House" else "S") + str(row["District"]),
    axis=1
)

df.head()

# Senate districts URL
senate_url = "https://services1.arcgis.com/99lidPhWCzftIe9K/arcgis/rest/services/UtahSenateDistricts2022to2032/FeatureServer/0/query"
params = {
    "where": "1=1",
    "outFields": "*",
    "outSR": "4326",
    "f": "geojson"   # <- request GeoJSON instead of JSON
}

# Request GeoJSON
response = requests.get(senate_url, params=params)
with open("senate.geojson", "wb") as f:
    f.write(response.content)

# Load into GeoDataFrame
senate_gdf = gpd.read_file("senate.geojson")

print(senate_gdf.columns)
senate_gdf.head()

senate_gdf['District'] = senate_gdf['DIST'].astype(int)
senate_gdf['Chamber'] = "Senate"
senate_gdf['DistrictKey'] = "S" + senate_gdf['District'].astype(str)

print(senate_gdf.columns)
senate_gdf.head()

senate_gdf.info()

house_url = "https://services1.arcgis.com/99lidPhWCzftIe9K/arcgis/rest/services/UtahHouseDistricts2022to2032/FeatureServer/0/query"

params["f"] = "geojson"  # reuse params
response = requests.get(house_url, params=params)
with open("house.geojson", "wb") as f:
    f.write(response.content)

house_gdf = gpd.read_file("house.geojson")

house_gdf['District'] = house_gdf['DIST'].astype(int)
house_gdf['Chamber'] = "House"
house_gdf['DistrictKey'] = "H" + house_gdf['District'].astype(str)

print(house_gdf.columns)
house_gdf.head()

house_gdf.info()

all_districts = pd.concat([senate_gdf, house_gdf], ignore_index=True)
all_districts = all_districts.reset_index(drop=True)

print(all_districts.columns)
print(all_districts.info())
all_districts.head()

# Ensure it's a GeoDataFrame
all_districts = gpd.GeoDataFrame(all_districts, geometry='geometry')

# Project to a projected CRS (UTM Zone 12N covers Utah)
all_districts = all_districts.to_crs(epsg=32612)

# Compute centroid in projected CRS
all_districts['centroid'] = all_districts.geometry.centroid

# Convert back to WGS84 for lat/lon
all_districts = all_districts.to_crs(epsg=4326)
all_districts['lat'] = all_districts['centroid'].y
all_districts['lon'] = all_districts['centroid'].x

# Convert geometry to WKT for polygon mapping
# all_districts['geometry_wkt'] = all_districts['geometry'].apply(lambda x: x.wkt if x else None)

all_districts.head()

# Simplify polygons (tolerance in degrees; smaller = more detail)
all_districts['geometry_simplified'] = all_districts['geometry'].simplify(0.01)

# Convert simplified geometry to WKT
all_districts['geometry_wkt'] = all_districts['geometry_simplified'].apply(lambda x: x.wkt if x else None)

all_districts.head()

# Merge the two dataframes on DistrictKey
all_data = pd.merge(df, all_districts, on="DistrictKey", how="left")

# Quick check
print(all_data.shape)
all_data.head()

# # trying to recreate the shape by generating lots of smaller points within the shape for looker studio. Not working for what i need

# # all_districts = your GeoDataFrame with geometry, Representative, DistrictKey, etc.

# points_list = []

# for idx, row in all_data.iterrows():
#     poly = row['geometry']
#     district_key = row['DistrictKey']
#     rep_name = row['Representative']

#     # Skip empty geometries
#     if poly is None or poly.is_empty:
#         continue

#     # --- 1. Add the centroid point ---
#     centroid = poly.centroid
#     points_list.append({
#         'DistrictKey': district_key,
#         'Representative': rep_name,
#         'lat': centroid.y,
#         'lon': centroid.x,
#         'Type': 'Centroid'
#     })

#     # --- 2. Add N random boundary points ---
#     N = 50  # adjust for more or fewer points
#     minx, miny, maxx, maxy = poly.bounds
#     count = 0
#     while count < N:
#         random_point = Point(random.uniform(minx, maxx), random.uniform(miny, maxy))
#         if poly.contains(random_point):
#             points_list.append({
#                 'DistrictKey': district_key,
#                 'Representative': rep_name,
#                 'lat': random_point.y,
#                 'lon': random_point.x,
#                 'Type': 'Boundary'
#             })
#             count += 1

# # Create a DataFrame of all points
# district_points_df = pd.DataFrame(points_list)

# # Optional: combined Location column for Looker Studio
# district_points_df['Location'] = district_points_df.apply(lambda r: f"{r['lat']},{r['lon']}", axis=1)

# district_points_df.head()

# Drop unnecessary columns
all_data = all_data.drop(columns=['District_x', 'Office', 'OBJECTID', 'DIST', 'District_y', 'centroid', 'geometry_simplified'], errors="ignore")

# Check result
all_data.head()

# Make sure lat and lon columns exist
# all_data['lat'] and all_data['lon'] from the centroid step

# Combine into a single location column
all_data['lat_lon'] = all_data.apply(lambda row: f"{row['lat']},{row['lon']}" if pd.notnull(row['lat']) and pd.notnull(row['lon']) else None, axis=1)

# Check
all_data[['lat','lon','lat_lon']].head()

all_data.info()

import os
import geopandas as gpd

# Ensure target folder exists
save_dir = "/content/drive/My Drive/ElectionTime/data/"
os.makedirs(save_dir, exist_ok=True)

# File paths
geojson_path = os.path.join(save_dir, "reps_with_geo_data.geojson")
json_path    = os.path.join(save_dir, "reps_with_geo_data.json")

# Make sure it's a GeoDataFrame
all_data = gpd.GeoDataFrame(all_data, geometry="geometry")

# Save full polygons as GeoJSON
all_data.to_file(geojson_path, driver="GeoJSON")

# Save attributes only as JSON
all_data.drop(columns="geometry").to_json(json_path, orient="records")

print(f"✅ Saved GeoJSON to {geojson_path}")
print(f"✅ Saved JSON to {json_path}")

# The geometry value is too big, the polygons have a lot of data.
# It was easier to download the geojson files locally for the next step of my process
# I plan to solve this problem in a scalable way


# Create or open the sheet
# try:
#     spreadsheet = gc.open("reps_with_geo_data")
# except gspread.SpreadsheetNotFound:
#     spreadsheet = gc.create("reps_with_geo_data")

# worksheet = spreadsheet.sheet1

# # Write the dataframe
# set_with_dataframe(worksheet, all_data)

# print("✅")